package question

import (
	"context"
	"database/sql"
	"log/slog"
	"strings"
	"time"

	"github.com/google/uuid"
	"github.com/pkg/errors"
	"github.com/sasalatart/quizory/domain/question/enums"
	"github.com/sasalatart/quizory/domain/question/internal/ai"
	"github.com/sasalatart/quizory/domain/question/internal/metrics"
	"github.com/sasalatart/quizory/llm"
)

// ErrNoQuestionsLeft is returned when there are no questions left to be answered for a user.
var ErrNoQuestionsLeft = errors.New("no questions left")

// Service represents the service that manages questions.
type Service struct {
	llmService     llm.ChatCompletioner
	metricsService metrics.Service
	repo           *Repository
}

// NewService creates a new instance of question.Service.
func NewService(
	llmService llm.ChatCompletioner,
	metricsService metrics.Service,
	repo *Repository,
) *Service {
	return &Service{
		llmService:     llmService,
		metricsService: metricsService,
		repo:           repo,
	}
}

// StartGeneration generates questions about random topics at a given frequency.
func (s Service) StartGeneration(ctx context.Context, freq time.Duration, batchSize int) {
	slog.Info("Starting questions generation loop", slog.Duration("freq", freq))

	ticker := time.NewTicker(freq)
	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			topic := enums.RandomTopic()
			slog.Info(
				"Generating questions",
				slog.String("topic", topic.String()),
				slog.Int("amount", batchSize),
			)
			if err := s.handleGeneration(ctx, topic, batchSize); err != nil {
				if errors.Is(err, context.Canceled) {
					return
				}
				slog.Error("Error generating question set", slog.Any("error", err))
			}
		}
	}
}

// handleGeneration generates and stores a set of questions about a given topic.
func (s Service) handleGeneration(ctx context.Context, topic enums.Topic, amount int) error {
	startTime := time.Now()

	results := make(chan ai.Result)
	defer close(results)

	recentlyGenerated, err := s.recentlyGenerated(ctx, topic, 100)
	if err != nil {
		return errors.Wrapf(err, "getting recently generated questions about %s", topic)
	}

	go ai.Generate(ctx, s.llmService, topic, recentlyGenerated, amount, results)

	select {
	case <-ctx.Done():
		return ctx.Err()
	case result := <-results:
		if result.Err != nil {
			return result.Err
		}

		questionsStored := 0
		for _, aiQuestion := range result.Questions {
			q, err := parseAIQuestion(aiQuestion, topic)
			if errors.Is(err, ErrInvalidRecord) {
				s.metricsService.OnFailedValidation(ctx)
				slog.Warn("Skipping invalid question", slog.Any("validationError", err))
				continue
			}
			if err != nil {
				return errors.Wrap(err, "parsing AI question")
			}
			slog.Info("Inserting question", slog.String("q", q.Question))
			if err := s.repo.Insert(context.WithoutCancel(ctx), *q); err != nil {
				return errors.Wrap(err, "inserting question")
			}
			questionsStored++
		}

		if questionsStored == len(result.Questions) {
			s.metricsService.OnSuccessfulGeneration(ctx)
		}
		s.metricsService.OnLLMCallFinished(ctx, time.Since(startTime))
	}
	return nil
}

// recentlyGenerated returns the most recent questions generated about a given topic.
func (s Service) recentlyGenerated(
	ctx context.Context,
	topic enums.Topic,
	amount int,
) ([]string, error) {
	questions, err := s.repo.GetMany(
		ctx,
		WhereTopicEq(topic),
		OrderByCreatedAtDesc(),
		Limit(amount),
	)
	if err != nil {
		return nil, err
	}
	var result []string
	for _, q := range questions {
		result = append(result, q.Question)
	}
	return result, nil
}

// parseAIQuestion converts an ai.Question to a Question. It may return an error if the conversion
// fails, since these questions are generated by the LLM.
func parseAIQuestion(aiQuestion ai.Question, topic enums.Topic) (*Question, error) {
	difficulty, err := enums.DifficultyString(aiQuestion.Difficulty)
	if err != nil {
		return nil, errors.Wrap(err, "parsing difficulty")
	}

	q := New(aiQuestion.Question, aiQuestion.Hint, strings.Join(aiQuestion.MoreInfo, "\n")).
		WithTopic(topic).
		WithDifficulty(difficulty)
	for _, c := range aiQuestion.Choices {
		q.WithChoice(c.Text, c.IsCorrect)
	}
	if err := q.Validate(); err != nil {
		return nil, err
	}
	return q, nil
}

// FromChoice returns the question associated with a given choice.
func (s Service) FromChoice(ctx context.Context, choiceID uuid.UUID) (*Question, error) {
	return s.repo.GetOne(ctx, WhereChoiceIDIn(choiceID))
}

// FromChoices returns the questions associated with a given set of choices.
func (s Service) FromChoices(ctx context.Context, ids ...uuid.UUID) ([]Question, error) {
	return s.repo.GetMany(ctx, WhereChoiceIDIn(ids...))
}

// NextFor returns the next question that a user should answer.
func (s Service) NextFor(
	ctx context.Context,
	userID uuid.UUID,
	topic enums.Topic,
) (*Question, error) {
	q, err := s.repo.GetOne(
		ctx,
		WhereTopicEq(topic),
		WhereNotAnsweredBy(userID),
		OrderByCreatedAtAsc(),
	)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, errors.Wrapf(
			ErrNoQuestionsLeft,
			"getting next question about %s for %s",
			topic, userID,
		)
	}
	return q, err
}

// RemainingTopicsFor returns a map such that each key is a topic for which the user still has
// unanswered questions, and each value is the amount of remaining questions for that topic.
func (s Service) RemainingTopicsFor(
	ctx context.Context,
	userID uuid.UUID,
) (map[enums.Topic]uint, error) {
	// Arguably the following logic could be owned by the service instead of the repository so that
	// we avoid making this a pass-through method. However, if we do this at the service level by
	// loading all unanswered questions for a user and grouping via code, we risk loading ALL
	// questions in the database in the worst case (e.g. if the user has not answered any question).
	// Thus, the tradeoff is to do this in the repository level, where we can leverage the database
	// to avoid this issue.
	return s.repo.GetRemainingTopics(ctx, userID)
}
